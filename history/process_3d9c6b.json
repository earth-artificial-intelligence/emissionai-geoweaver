[{
  "history_id" : "pen85simzfo",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "",
  "history_begin_time" : 1651521836176,
  "history_end_time" : 1651521841660,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6183w0hb967",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "",
  "history_begin_time" : 1649179884425,
  "history_end_time" : 1649179888219,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "YNFNlYKklD0V",
  "history_input" : "import subprocess\nimport sys\nimport math\n\ntry:\n\timport pandas as pd\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport seaborn as sns\n\timport sklearn\n\timport keras\n\timport tensorflow\nexcept ImportError:\n\tsubprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tensorflow', 'scikit-learn', 'pandas', 'matplotlib', 'seaborn'])\nfinally:\n\timport tensorflow as tf\n\tfrom keras.models import Sequential\n\tfrom keras.layers import Dense\n\tfrom keras.layers import LSTM\n\tfrom sklearn.model_selection import train_test_split\n\tfrom sklearn.preprocessing import MinMaxScaler\n\tfrom sklearn.metrics import mean_squared_error\n\tfrom sklearn import metrics\n\tfrom sklearn.externals import joblib\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport seaborn as sns\n\timport pandas as pd\n\t\n\nmatplotlib.use('Agg')\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\n#showAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\n#plt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\n#plt.title('model loss')\n#plt.ylabel('loss')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'validation'], loc='upper left')\n#plt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)\n\njoblib.dump(model, '~/Deep_NN.pkl')",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 24, in <module>\n    from sklearn.externals import joblib\nImportError: cannot import name 'joblib' from 'sklearn.externals' (/opt/anaconda3/lib/python3.8/site-packages/sklearn/externals/__init__.py)\n",
  "history_begin_time" : 1645156604964,
  "history_end_time" : 1645156613255,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "3TiyFiQr7fSO",
  "history_input" : "import subprocess\nimport sys\nimport math\n\ntry:\n\timport pandas as pd\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport seaborn as sns\n\timport sklearn\n\timport keras\n\timport tensorflow\nexcept ImportError:\n\tsubprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tensorflow', 'scikit-learn', 'pandas', 'matplotlib', 'seaborn'])\nfinally:\n\timport tensorflow as tf\n\tfrom keras.models import Sequential\n\tfrom keras.layers import Dense\n\tfrom keras.layers import LSTM\n\tfrom sklearn.model_selection import train_test_split\n\tfrom sklearn.preprocessing import MinMaxScaler\n\tfrom sklearn.metrics import mean_squared_error\n\tfrom sklearn import metrics\n\tfrom sklearn.externals import joblib\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport seaborn as sns\n\timport pandas as pd\n\t\n\nmatplotlib.use('Agg')\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\n#showAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\n#plt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\n#plt.title('model loss')\n#plt.ylabel('loss')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'validation'], loc='upper left')\n#plt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)\n\njoblib.dump(model, '~/Deep_NN.pkl')",
  "history_output" : "Running",
  "history_begin_time" : 1645156573915,
  "history_end_time" : 1645156578305,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "lDAQy6ScBF87",
  "history_input" : "import subprocess\nimport sys\nimport math\n\ntry:\n\timport pandas as pd\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport seaborn as sns\n\timport sklearn\n\timport keras\n\timport tensorflow\nexcept ImportError:\n\tsubprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tensorflow', 'scikit-learn', 'pandas', 'matplotlib', 'seaborn'])\nfinally:\n\timport tensorflow as tf\n\tfrom keras.models import Sequential\n\tfrom keras.layers import Dense\n\tfrom keras.layers import LSTM\n\tfrom sklearn.model_selection import train_test_split\n\tfrom sklearn.preprocessing import MinMaxScaler\n\tfrom sklearn.metrics import mean_squared_error\n\tfrom sklearn import metrics\n\tfrom sklearn.externals import joblib\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport seaborn as sns\n\timport pandas as pd\n\t\n\nmatplotlib.use('Agg')\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\n#showAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\n#plt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\n#plt.title('model loss')\n#plt.ylabel('loss')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'validation'], loc='upper left')\n#plt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)\n\njoblib.dump(model, '~/Deep_NN.pkl')",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 24, in <module>\n    from sklearn.externals import joblib\nImportError: cannot import name 'joblib' from 'sklearn.externals' (/opt/anaconda3/lib/python3.8/site-packages/sklearn/externals/__init__.py)\n",
  "history_begin_time" : 1645156542950,
  "history_end_time" : 1645156562145,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "1khzuup279t",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1643666955996,
  "history_end_time" : 1643666956014,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "u7t6nc1pblx",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "",
  "history_begin_time" : 1643125050241,
  "history_end_time" : 1643125051434,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7mr0l77u65c",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1642966287834,
  "history_end_time" : 1642966287857,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "y86b8a15tct",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1642958113719,
  "history_end_time" : 1642958113810,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "50rctyforaj",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "  File \"DeepLearning_NN.py\", line 19\n    emissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n                                                                                       ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1642316565509,
  "history_end_time" : 1642316565905,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "c21fdnhv2nk",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2022-01-15 02:51:52.536759: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-01-15 02:51:52.539744: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-01-15 02:51:52.629970: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 2s - loss: 0.6154 - mean_squared_error: 0.6154 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 1s 35ms/step - loss: 0.6391 - mean_squared_error: 0.6391 - accuracy: 0.0000e+00 - val_loss: 0.6160 - val_mean_squared_error: 0.6160 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.5806 - mean_squared_error: 0.5806 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.4734 - mean_squared_error: 0.4734 - accuracy: 0.0000e+00 - val_loss: 0.0299 - val_mean_squared_error: 0.0299 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0682 - mean_squared_error: 0.0682 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - accuracy: 0.0000e+00 - val_loss: 0.0203 - val_mean_squared_error: 0.0203 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0228 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0265 - mean_squared_error: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0197 - val_mean_squared_error: 0.0197 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0182 - val_mean_squared_error: 0.0182 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0323 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - mean_squared_error: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0164 - val_mean_squared_error: 0.0164 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0276 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0222 - mean_squared_error: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_mean_squared_error: 0.0130 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0162 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0193 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0188 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0205 - mean_squared_error: 0.0205 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_mean_squared_error: 0.0065 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0167 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_mean_squared_error: 0.0065 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_mean_squared_error: 0.0072 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_mean_squared_error: 0.0070 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_mean_squared_error: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0014 - mean_squared_error: 0.0014 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nUsing TensorFlow backend.\nModel  Neural Network:   Performance:\n   MAE:  0.07927884080716542\n   MSE:  0.010206208940509732\n   R2:  -0.0022138240131301945\n",
  "history_begin_time" : 1642233101394,
  "history_end_time" : 1642233116623,
  "history_notes" : "0.01",
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lnegfqcf4ai",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "",
  "history_begin_time" : 1642233052514,
  "history_end_time" : 1642233054278,
  "history_notes" : "failed",
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7hch2s7rx6s",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2022-01-15 02:02:46.311983: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-01-15 02:02:46.312241: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-01-15 02:02:46.371983: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 2s - loss: 0.0201 - mean_squared_error: 0.0201 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 1s 37ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_mean_squared_error: 0.0121 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_mean_squared_error: 0.0107 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 7.6723e-04 - mean_squared_error: 7.6723e-04 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0208 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0169 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0196 - mean_squared_error: 0.0196 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0123 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0209 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0114 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0178 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0016 - mean_squared_error: 0.0016 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 5.8231e-04 - mean_squared_error: 5.8231e-04 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nUsing TensorFlow backend.\nModel  Neural Network:   Performance:\n   MAE:  0.07322475320543563\n   MSE:  0.00878420687675723\n   R2:  -0.003619010806415357\n",
  "history_begin_time" : 1642230162203,
  "history_end_time" : 1642230170082,
  "history_notes" : "0.008",
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7kq93bmx5c6",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2022-01-15 02:02:03.737156: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-01-15 02:02:03.737425: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-01-15 02:02:03.792057: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 2s - loss: 0.0256 - mean_squared_error: 0.0256 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 1s 35ms/step - loss: 0.0427 - mean_squared_error: 0.0427 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0288 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0474 - mean_squared_error: 0.0474 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0762 - mean_squared_error: 0.0762 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0538 - mean_squared_error: 0.0538 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0410 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0450 - mean_squared_error: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.0601 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0484 - mean_squared_error: 0.0484 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0534 - mean_squared_error: 0.0534 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0518 - mean_squared_error: 0.0518 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.0583 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0421 - mean_squared_error: 0.0421 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0650 - mean_squared_error: 0.0650 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0507 - mean_squared_error: 0.0507 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0577 - mean_squared_error: 0.0577 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0493 - mean_squared_error: 0.0493 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0772 - mean_squared_error: 0.0772 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0520 - mean_squared_error: 0.0520 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0420 - mean_squared_error: 0.0420 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0476 - mean_squared_error: 0.0476 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0567 - mean_squared_error: 0.0567 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0491 - mean_squared_error: 0.0491 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0596 - mean_squared_error: 0.0596 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 5/11 [============>.................] - ETA: 0s - loss: 0.0468 - mean_squared_error: 0.0468 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 9ms/step - loss: 0.0464 - mean_squared_error: 0.0464 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0445 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0470 - mean_squared_error: 0.0470 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0330 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0451 - mean_squared_error: 0.0451 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0509 - mean_squared_error: 0.0509 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0454 - mean_squared_error: 0.0454 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0357 - mean_squared_error: 0.0357 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0442 - mean_squared_error: 0.0442 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0209 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0469 - mean_squared_error: 0.0469 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0404 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0433 - mean_squared_error: 0.0433 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0718 - mean_squared_error: 0.0718 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0531 - mean_squared_error: 0.0531 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0425 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0501 - mean_squared_error: 0.0501 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0551 - mean_squared_error: 0.0551 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0306 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0409 - mean_squared_error: 0.0409 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0384 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0498 - mean_squared_error: 0.0498 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.0566 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0463 - mean_squared_error: 0.0463 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0469 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0424 - mean_squared_error: 0.0424 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0435 - mean_squared_error: 0.0435 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0354 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0416 - mean_squared_error: 0.0416 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0720 - mean_squared_error: 0.0720 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0527 - mean_squared_error: 0.0527 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0371 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0440 - mean_squared_error: 0.0440 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0461 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0453 - mean_squared_error: 0.0453 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0478 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0502 - mean_squared_error: 0.0502 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0396 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0459 - mean_squared_error: 0.0459 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0440 - mean_squared_error: 0.0440 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0426 - mean_squared_error: 0.0426 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.0611 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0334 - mean_squared_error: 0.0334 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0419 - mean_squared_error: 0.0419 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0395 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0427 - mean_squared_error: 0.0427 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0435 - mean_squared_error: 0.0435 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0564 - mean_squared_error: 0.0564 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0311 - mean_squared_error: 0.0311 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0458 - mean_squared_error: 0.0458 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0510 - mean_squared_error: 0.0510 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0464 - mean_squared_error: 0.0464 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.0841 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0564 - mean_squared_error: 0.0564 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0590 - mean_squared_error: 0.0590 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0495 - mean_squared_error: 0.0495 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0711 - mean_squared_error: 0.0711 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0505 - mean_squared_error: 0.0505 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0660 - mean_squared_error: 0.0660 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0532 - mean_squared_error: 0.0532 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.0532 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0473 - mean_squared_error: 0.0473 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0371 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0407 - mean_squared_error: 0.0407 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0565 - mean_squared_error: 0.0565 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0500 - mean_squared_error: 0.0500 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.0304 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.0553 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_mean_squared_error: 0.0624 - val_accuracy: 0.0000e+00\nUsing TensorFlow backend.\nModel  Neural Network:   Performance:\n   MAE:  0.20796842282502934\n   MSE:  0.050495070160929086\n   R2:  -5.970348725303492\n",
  "history_begin_time" : 1642230119283,
  "history_end_time" : 1642230127637,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4juzyhh05zq",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2022-01-15 01:53:23.542585: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-01-15 01:53:23.542873: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-01-15 01:53:23.608512: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 2s - loss: 0.0172 - mean_squared_error: 0.0172 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 1s 35ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_mean_squared_error: 0.0106 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0186 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0174 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0014 - mean_squared_error: 0.0014 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0015 - mean_squared_error: 0.0015 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0202 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0163 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0203 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nUsing TensorFlow backend.\nModel  Neural Network:   Performance:\n   MAE:  0.0736487099649225\n   MSE:  0.010467518877552845\n   R2:  -0.056742690587904265\nTraceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 67, in <module>\n    plt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/pyplot.py\", line 958, in savefig\n    res = fig.savefig(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/figure.py\", line 3019, in savefig\n    self.canvas.print_figure(fname, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/backend_bases.py\", line 2319, in print_figure\n    result = print_method(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/backend_bases.py\", line 1648, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/_api/deprecation.py\", line 412, in wrapper\n    return func(*inner_args, **inner_kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 541, in print_png\n    mpl.image.imsave(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/image.py\", line 1675, in imsave\n    image.save(fname, **pil_kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/envs/py38/lib/python3.8/site-packages/PIL/Image.py\", line 2209, in save\n    fp = builtins.open(filename, \"w+b\")\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/uhhmed/geoweaver_demo/NN_modelLoss.png'\n",
  "history_begin_time" : 1642229599100,
  "history_end_time" : 1642229607386,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "56xag07ctb4",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/IvVcvGAPWicX6QtLoOIl42SpPq/DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n    from tensorflow.python import tf2\nModuleNotFoundError: No module named 'tensorflow'\n",
  "history_begin_time" : 1642227727243,
  "history_end_time" : 1642227730362,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zmylygbjx7s",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1642226787679,
  "history_end_time" : 1642226787809,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qizwiaxdaz0",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/FHBltUq23tcRqJRjQi1vIq0Zfz/DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n    from tensorflow.python import tf2\nModuleNotFoundError: No module named 'tensorflow'\n",
  "history_begin_time" : 1642116751530,
  "history_end_time" : 1642116754541,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ccw1h7upfun",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1642116684917,
  "history_end_time" : 1642116684939,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "filivax8ra2",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/LPJLZuv0nFNvJvvAahNHTv0kES/DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n    from tensorflow.python import tf2\nModuleNotFoundError: No module named 'tensorflow'\n",
  "history_begin_time" : 1642022966557,
  "history_end_time" : 1642022969954,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "40hz57csu3s",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1642022911781,
  "history_end_time" : 1642022911910,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1pj8xj69pq1",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "mkdir: cannot create directory 0xnAYVrHPLbKB8Y3PUj1X2ZZig: File exists\nloop.py\nGetEmissionsData.py\nExploreDataProperties.py\nVisualizeFeatures.py\nDeepLearning_NN.py\nTrainModel_LSTM.py\ntest1.py\nData Preprocessing.py\nSVR Model.py\nRandom Forest Model.py\nDeploy ML.py\npython: can't open file 'DeepLearning_NN.py': [Errno 2] No such file or directory\nrm: cannot remove '0xnAYVrHPLbKB8Y3PUj1X2ZZig*': No such file or directory\n",
  "history_begin_time" : 1641216004673,
  "history_end_time" : 1641216009930,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "t5g55h",
  "indicator" : "Done"
},{
  "history_id" : "41624gjm973",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-12-13 08:51:04.408371: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-12-13 08:51:04.668736: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:35 - loss: 0.5959 - mean_squared_error: 0.5959 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 10s 50ms/step - loss: 0.6235 - mean_squared_error: 0.6235 - accuracy: 0.0000e+00 - val_loss: 0.5464 - val_mean_squared_error: 0.5464 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.5234 - mean_squared_error: 0.5234 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.4899 - mean_squared_error: 0.4899 - accuracy: 0.0000e+00 - val_loss: 0.0158 - val_mean_squared_error: 0.0158 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0185 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0167 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_mean_squared_error: 0.0094 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0178 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.07003583306925638\n   MSE:  0.008750936192571147\n   R2:  0.17875279916899445\n",
  "history_begin_time" : 1639374655770,
  "history_end_time" : 1639374678855,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},{
  "history_id" : "xinnrfrgst9",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/l21-n02609-comm/gw-workspace/5eOIwUMcySnvilUCs7sVVpsGZl/DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n    from tensorflow.python import tf2\nModuleNotFoundError: No module named 'tensorflow'\n",
  "history_begin_time" : 1639373559395,
  "history_end_time" : 1639373561349,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l48c3w0pi5k",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/l21-n02609-comm/gw-workspace/5eOIwUMcySnvilUCs7sVVpsGZl/DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n    from tensorflow.python import tf2\nModuleNotFoundError: No module named 'tensorflow'\n",
  "history_begin_time" : 1639372900519,
  "history_end_time" : 1639372902926,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3pfbahiq9po",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/l21-n02609-comm/gw-workspace/5eOIwUMcySnvilUCs7sVVpsGZl/DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\nModuleNotFoundError: No module named 'keras'\n",
  "history_begin_time" : 1639372542947,
  "history_end_time" : 1639372547431,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ycm7goupqv9",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639345545330,
  "history_end_time" : 1639345545456,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "btgi69mudf0",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639345438154,
  "history_end_time" : 1639345438274,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "258f64dcbii",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1639345393366,
  "history_end_time" : 1639345393387,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "fhgjeli6atu",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1639345254252,
  "history_end_time" : 1639345254269,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "v9jezbjaksa",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1639344892483,
  "history_end_time" : 1639344892504,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "0f40rnqi61m",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639326043058,
  "history_end_time" : 1639326043190,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q11mk7j2zcn",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1639325968225,
  "history_end_time" : 1639325968264,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "z3vzfnzaxae",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1639325950958,
  "history_end_time" : 1639325950980,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "wia09fppssj",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639324419567,
  "history_end_time" : 1639324419693,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "24vnlxxhs23",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639324286258,
  "history_end_time" : 1639324286458,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ciwywukzw5m",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639324213249,
  "history_end_time" : 1639324213409,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "45elt443xnj",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639324159350,
  "history_end_time" : 1639324159517,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uf8qx4qgbww",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639282298284,
  "history_end_time" : 1639282298408,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "w872704kq0r",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1639281631439,
  "history_end_time" : 1639281631583,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "o4a14prrzo6",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1639280124913,
  "history_end_time" : 1639280124929,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pc2d00ocf46",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Using TensorFlow backend.\nTraceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/__init__.py\", line 3, in <module>\n    from . import utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/__init__.py\", line 6, in <module>\n    from . import conv_utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/conv_utils.py\", line 9, in <module>\n    from .. import backend as K\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/__init__.py\", line 1, in <module>\n    from .load_backend import epsilon\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/load_backend.py\", line 90, in <module>\n    from .tensorflow_backend import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 5, in <module>\n    import tensorflow as tf\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\n  File \"/home/zsun/.local/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 113\n    class DescriptorBase(metaclass=DescriptorMetaclass):\n                                  ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1636386562776,
  "history_end_time" : 1636386566328,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "27efn530drb",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Using TensorFlow backend.\nTraceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/__init__.py\", line 3, in <module>\n    from . import utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/__init__.py\", line 6, in <module>\n    from . import conv_utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/conv_utils.py\", line 9, in <module>\n    from .. import backend as K\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/__init__.py\", line 1, in <module>\n    from .load_backend import epsilon\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/load_backend.py\", line 90, in <module>\n    from .tensorflow_backend import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 5, in <module>\n    import tensorflow as tf\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\n  File \"/home/zsun/.local/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 113\n    class DescriptorBase(metaclass=DescriptorMetaclass):\n                                  ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1636145204034,
  "history_end_time" : 1636145205977,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "tw7vx7pl67l",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 3, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1636062897977,
  "history_end_time" : 1636062898799,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "27q7yrtw4lo",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Using TensorFlow backend.\nTraceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/__init__.py\", line 3, in <module>\n    from . import utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/__init__.py\", line 6, in <module>\n    from . import conv_utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/conv_utils.py\", line 9, in <module>\n    from .. import backend as K\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/__init__.py\", line 1, in <module>\n    from .load_backend import epsilon\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/load_backend.py\", line 90, in <module>\n    from .tensorflow_backend import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 5, in <module>\n    import tensorflow as tf\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\n  File \"/home/zsun/.local/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 113\n    class DescriptorBase(metaclass=DescriptorMetaclass):\n                                  ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1636062731096,
  "history_end_time" : 1636062732361,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mx829u12lx0",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Using TensorFlow backend.\nTraceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/__init__.py\", line 3, in <module>\n    from . import utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/__init__.py\", line 6, in <module>\n    from . import conv_utils\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/utils/conv_utils.py\", line 9, in <module>\n    from .. import backend as K\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/__init__.py\", line 1, in <module>\n    from .load_backend import epsilon\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/load_backend.py\", line 90, in <module>\n    from .tensorflow_backend import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 5, in <module>\n    import tensorflow as tf\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/home/zsun/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\n  File \"/home/zsun/.local/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 113\n    class DescriptorBase(metaclass=DescriptorMetaclass):\n                                  ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1636062670154,
  "history_end_time" : 1636062671467,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3utrvvtt348",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-11-05 00:46:23.486296: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-05 00:46:23.720131: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:32 - loss: 0.0520 - mean_squared_error: 0.0520 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 10s 52ms/step - loss: 0.0442 - mean_squared_error: 0.0442 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_mean_squared_error: 0.0265 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0080 - mean_squared_error: 0.0080 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_mean_squared_error: 0.0125 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0156 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_mean_squared_error: 0.0097 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_mean_squared_error: 0.0094 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_mean_squared_error: 0.0098 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_mean_squared_error: 0.0098 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_mean_squared_error: 0.0113 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_mean_squared_error: 0.0097 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0017 - mean_squared_error: 0.0017 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0055 - mean_squared_error: 0.0055 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0055 - mean_squared_error: 0.0055 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_mean_squared_error: 0.0113 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_mean_squared_error: 0.0105 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_mean_squared_error: 0.0098 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0015 - mean_squared_error: 0.0015 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_mean_squared_error: 0.0107 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 5.1168e-04 - mean_squared_error: 5.1168e-04 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_mean_squared_error: 0.0097 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 8.6303e-04 - mean_squared_error: 8.6303e-04 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_mean_squared_error: 0.0098 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_mean_squared_error: 0.0097 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0113 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0122 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0201 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.06990576907328197\n   MSE:  0.00853654545506056\n   R2:  0.14067248799920296\n",
  "history_begin_time" : 1636062377487,
  "history_end_time" : 1636062397368,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},{
  "history_id" : "mh48h00reum",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-11-05 00:44:48.231482: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-05 00:44:48.473675: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:36 - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 10s 50ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_mean_squared_error: 0.0127 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_mean_squared_error: 0.0115 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_mean_squared_error: 0.0124 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0181 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_mean_squared_error: 0.0098 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0236 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_mean_squared_error: 0.0094 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0188 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0055 - mean_squared_error: 0.0055 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_mean_squared_error: 0.0094 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_mean_squared_error: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0157 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_mean_squared_error: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.07265906857643809\n   MSE:  0.009174212123331067\n   R2:  -0.00545773515639425\n",
  "history_begin_time" : 1636062280626,
  "history_end_time" : 1636062302569,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},{
  "history_id" : "u1tryt5slhf",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636052899658,
  "history_end_time" : 1636052900977,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "v8gwbuf2ej1",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636043261148,
  "history_end_time" : 1636043262694,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "iap068x9pmj",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636037962215,
  "history_end_time" : 1636037983183,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},{
  "history_id" : "7en312ixlmd",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-11-04 17:55:54.621151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-04 17:55:54.881235: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:37 - loss: 0.0434 - mean_squared_error: 0.0434 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 10s 55ms/step - loss: 0.0474 - mean_squared_error: 0.0474 - accuracy: 0.0000e+00 - val_loss: 0.0379 - val_mean_squared_error: 0.0379 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0489 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0405 - mean_squared_error: 0.0405 - accuracy: 0.0000e+00 - val_loss: 0.0344 - val_mean_squared_error: 0.0344 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0637 - mean_squared_error: 0.0637 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0392 - val_mean_squared_error: 0.0392 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0302 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - accuracy: 0.0000e+00 - val_loss: 0.0361 - val_mean_squared_error: 0.0361 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0175 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0268 - mean_squared_error: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0335 - val_mean_squared_error: 0.0335 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0253 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0249 - mean_squared_error: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0314 - val_mean_squared_error: 0.0314 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0164 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0255 - mean_squared_error: 0.0255 - accuracy: 0.0000e+00 - val_loss: 0.0297 - val_mean_squared_error: 0.0297 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0385 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_mean_squared_error: 0.0259 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - accuracy: 0.0000e+00 - val_loss: 0.0188 - val_mean_squared_error: 0.0188 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_mean_squared_error: 0.0110 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0318 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_mean_squared_error: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0194 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_mean_squared_error: 0.0068 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_mean_squared_error: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0166 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_mean_squared_error: 0.0068 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_mean_squared_error: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0012 - mean_squared_error: 0.0012 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_mean_squared_error: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_mean_squared_error: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 9.7844e-04 - mean_squared_error: 9.7844e-04 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_mean_squared_error: 0.0048 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.0800796308028698\n   MSE:  0.01068909260256273\n   R2:  -0.003254302821038113\n",
  "history_begin_time" : 1636037746639,
  "history_end_time" : 1636037769120,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},{
  "history_id" : "g6y6ch6wrdr",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636037700160,
  "history_end_time" : 1636037701310,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "evdsx1ruhxn",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\nImportError: No module named keras.models\n",
  "history_begin_time" : 1636037532198,
  "history_end_time" : 1636037533396,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z246e2v91r6",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636037159337,
  "history_end_time" : 1636037160562,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3xtjm00w8fe",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636037119559,
  "history_end_time" : 1636037120793,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wz2fpye8ta0",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-11-04 17:43:10.797766: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-04 17:43:11.078150: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:40 - loss: 0.0539 - mean_squared_error: 0.0539 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 11s 58ms/step - loss: 0.0507 - mean_squared_error: 0.0507 - accuracy: 0.0000e+00 - val_loss: 0.0413 - val_mean_squared_error: 0.0413 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0580 - mean_squared_error: 0.0580 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0519 - mean_squared_error: 0.0519 - accuracy: 0.0000e+00 - val_loss: 0.0384 - val_mean_squared_error: 0.0384 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0369 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0429 - mean_squared_error: 0.0429 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0191 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - accuracy: 0.0000e+00 - val_loss: 0.0194 - val_mean_squared_error: 0.0194 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - accuracy: 0.0000e+00 - val_loss: 0.0170 - val_mean_squared_error: 0.0170 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0367 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - accuracy: 0.0000e+00 - val_loss: 0.0161 - val_mean_squared_error: 0.0161 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0308 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.0189 - val_mean_squared_error: 0.0189 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_mean_squared_error: 0.0109 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0280 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_mean_squared_error: 0.0105 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_mean_squared_error: 0.0098 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_mean_squared_error: 0.0126 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0213 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0232 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0221 - mean_squared_error: 0.0221 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_mean_squared_error: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0157 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0226 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_mean_squared_error: 0.0069 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_mean_squared_error: 0.0070 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_mean_squared_error: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_mean_squared_error: 0.0068 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 9.2403e-04 - mean_squared_error: 9.2403e-04 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_mean_squared_error: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_mean_squared_error: 0.0072 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_mean_squared_error: 0.0070 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.06660542702181\n   MSE:  0.0075670377167778025\n   R2:  0.09286422289647589\n",
  "history_begin_time" : 1636036983339,
  "history_end_time" : 1636037005609,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},{
  "history_id" : "t3p7zlnr5m3",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036824591,
  "history_end_time" : 1636036825754,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0vxbaffkpj2",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036575796,
  "history_end_time" : 1636036577009,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1i1vqtibejv",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036494942,
  "history_end_time" : 1636036496164,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4rgebhjtdd0",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036417443,
  "history_end_time" : 1636036418198,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0c2y8g4xm0v",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036327987,
  "history_end_time" : 1636036328805,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2v64wo28gys",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036306938,
  "history_end_time" : 1636036307688,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "93375hbvbgz",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 2, in <module>\n    import matplotlib.pyplot as plt\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 115, in <module>\n    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 63, in pylab_setup\n    [backend_name], 0)\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backends/backend_tkagg.py\", line 4, in <module>\n    from . import tkagg  # Paint image to Tk photo blitter extension.\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backends/tkagg.py\", line 5, in <module>\n    from six.moves import tkinter as Tk\n  File \"/home/zsun/.local/lib/python2.7/site-packages/six.py\", line 213, in load_module\n    mod = mod._resolve()\n  File \"/home/zsun/.local/lib/python2.7/site-packages/six.py\", line 120, in _resolve\n    return _import_module(self.mod)\n  File \"/home/zsun/.local/lib/python2.7/site-packages/six.py\", line 87, in _import_module\n    __import__(name)\n  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 42, in <module>\n    raise ImportError, str(msg) + ', please install the python-tk package'\nImportError: No module named _tkinter, please install the python-tk package\n",
  "history_begin_time" : 1636036263831,
  "history_end_time" : 1636036264597,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ciwlcj80m9o",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036132769,
  "history_end_time" : 1636036133521,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vui8fdsibp9",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036086418,
  "history_end_time" : 1636036087236,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5pecz6hjllj",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636036024373,
  "history_end_time" : 1636036025122,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2xw8o3c234a",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1636035960887,
  "history_end_time" : 1636035960899,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "qp3efjd0tq9",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 2, in <module>\n    import matplotlib.pyplot as plt\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 115, in <module>\n    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 63, in pylab_setup\n    [backend_name], 0)\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backends/backend_tkagg.py\", line 4, in <module>\n    from . import tkagg  # Paint image to Tk photo blitter extension.\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backends/tkagg.py\", line 5, in <module>\n    from six.moves import tkinter as Tk\n  File \"/home/zsun/.local/lib/python2.7/site-packages/six.py\", line 213, in load_module\n    mod = mod._resolve()\n  File \"/home/zsun/.local/lib/python2.7/site-packages/six.py\", line 120, in _resolve\n    return _import_module(self.mod)\n  File \"/home/zsun/.local/lib/python2.7/site-packages/six.py\", line 87, in _import_module\n    __import__(name)\n  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 42, in <module>\n    raise ImportError, str(msg) + ', please install the python-tk package'\nImportError: No module named _tkinter, please install the python-tk package\n",
  "history_begin_time" : 1636035829236,
  "history_end_time" : 1636035829980,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "n2iepyn9k9l",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-11-04 17:09:58.155370: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-04 17:09:58.433815: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:41 - loss: 0.0181 - mean_squared_error: 0.0181 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 11s 52ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0209 - val_mean_squared_error: 0.0209 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0196 - val_mean_squared_error: 0.0196 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0186 - val_mean_squared_error: 0.0186 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0180 - val_mean_squared_error: 0.0180 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0174 - val_mean_squared_error: 0.0174 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0179 - val_mean_squared_error: 0.0179 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0167 - val_mean_squared_error: 0.0167 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0166 - val_mean_squared_error: 0.0166 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0166 - val_mean_squared_error: 0.0166 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0074 - mean_squared_error: 0.0074 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0160 - val_mean_squared_error: 0.0160 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0157 - val_mean_squared_error: 0.0157 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0163 - val_mean_squared_error: 0.0163 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0155 - val_mean_squared_error: 0.0155 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0154 - val_mean_squared_error: 0.0154 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 9/11 [=======================>......] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 8ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0151 - val_mean_squared_error: 0.0151 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0017 - mean_squared_error: 0.0017 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 7/11 [==================>...........] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 10ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0016 - mean_squared_error: 0.0016 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0012 - mean_squared_error: 0.0012 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0055 - mean_squared_error: 0.0055 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0010 - mean_squared_error: 0.0010 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_mean_squared_error: 0.0133 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 9ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_mean_squared_error: 0.0134 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 9.6758e-04 - mean_squared_error: 9.6758e-04 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_mean_squared_error: 0.0135 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.08390790675452776\n   MSE:  0.01181245064594315\n   R2:  -0.13313420718658286\n",
  "history_begin_time" : 1636034990364,
  "history_end_time" : 1636035013216,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q6r1lpoh4vu",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636034773201,
  "history_end_time" : 1636034774026,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "87belztgj1h",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636034555986,
  "history_end_time" : 1636034556777,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ra2d9xc2cvz",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 2, in <module>\n    import matplotlib.pyplot as plt\nImportError: No module named matplotlib.pyplot\n",
  "history_begin_time" : 1636034395494,
  "history_end_time" : 1636034395834,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kgudvk0opt0",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 2, in <module>\n    import matplotlib.pyplot as plt\nImportError: No module named matplotlib.pyplot\n",
  "history_begin_time" : 1636034361321,
  "history_end_time" : 1636034361631,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "b242t17sw1j",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636033773936,
  "history_end_time" : 1636033773975,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vhjl8lq9wq4",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636033715622,
  "history_end_time" : 1636033715671,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u4pzbh91s10",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"DeepLearning_NN.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1636033714861,
  "history_end_time" : 1636033714886,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0qvs3i173ye",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-11-04 04:17:13.631368: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-04 04:17:13.898181: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:35 - loss: 0.0447 - mean_squared_error: 0.0447 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 10s 53ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_mean_squared_error: 0.0355 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0489 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0431 - mean_squared_error: 0.0431 - accuracy: 0.0000e+00 - val_loss: 0.0197 - val_mean_squared_error: 0.0197 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0391 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0294 - mean_squared_error: 0.0294 - accuracy: 0.0000e+00 - val_loss: 0.0184 - val_mean_squared_error: 0.0184 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0198 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0241 - mean_squared_error: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0169 - val_mean_squared_error: 0.0169 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0202 - mean_squared_error: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0196 - mean_squared_error: 0.0196 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_mean_squared_error: 0.0133 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_mean_squared_error: 0.0107 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0338 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - mean_squared_error: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0237 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_mean_squared_error: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0247 - mean_squared_error: 0.0247 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_mean_squared_error: 0.0065 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0115 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_mean_squared_error: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0122 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0139 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0158 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_mean_squared_error: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0206 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0186 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 5ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.05619425083824566\n   MSE:  0.005172279659471195\n   R2:  0.055166569722880254\n",
  "history_begin_time" : 1635988625556,
  "history_end_time" : 1635988648003,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},{
  "history_id" : "w3pdkym7bve",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "2021-11-03 00:04:30.412640: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-11-03 00:04:30.734657: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 500)               6500      \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_2 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_3 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_4 (Dense)              (None, 500)               250500    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 1,009,001\nTrainable params: 1,009,001\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n 1/11 [=>............................] - ETA: 1:55 - loss: 0.0861 - mean_squared_error: 0.0861 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 12s 65ms/step - loss: 0.0547 - mean_squared_error: 0.0547 - accuracy: 0.0000e+00 - val_loss: 0.0151 - val_mean_squared_error: 0.0151 - val_accuracy: 0.0000e+00\nEpoch 2/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0204 - mean_squared_error: 0.0204 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_accuracy: 0.0000e+00\nEpoch 3/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0197 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 4/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 5/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 6/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0218 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 7/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 8/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 9/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 10/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0017 - mean_squared_error: 0.0017 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 11/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 12/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 13/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 14/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 15/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - ETA: 0s - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 8ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 16/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 17/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0083 - mean_squared_error: 0.0083 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 8ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 18/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 19/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 20/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 21/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 22/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 23/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_mean_squared_error: 0.0101 - val_accuracy: 0.0000e+00\nEpoch 24/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 25/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 26/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 27/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 28/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 29/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 9ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 30/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 31/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 32/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 33/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 34/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 35/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 8ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 36/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 37/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 38/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_mean_squared_error: 0.0105 - val_accuracy: 0.0000e+00\nEpoch 39/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 40/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 41/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 42/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 43/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0108 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 44/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 45/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 46/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0013 - mean_squared_error: 0.0013 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 47/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 48/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0080 - mean_squared_error: 0.0080 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 6ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 49/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 50/50\n 1/11 [=>............................] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048 - accuracy: 0.0000e+00\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n11/11 [==============================] - 0s 7ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_mean_squared_error: 0.0103 - val_accuracy: 0.0000e+00\nModel  Neural Network:   Performance:\n   MAE:  0.08382794874480792\n   MSE:  0.010942551632955494\n   R2:  -0.05774952280120038\n",
  "history_begin_time" : 1635887062034,
  "history_end_time" : 1635887087732,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "22hpox",
  "indicator" : "Done"
},]
