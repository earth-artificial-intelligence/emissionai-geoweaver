[{
  "history_id" : "oi1o5syrh8m",
  "history_input" : "import pandas as pd\nemissions = pd.read_csv('https://raw.githubusercontent.com/ZihengSun/EmissionAI/main/data/tropomi_epa_kvps_NO2_2019_56.csv' , parse_dates=[\"Date\"])\nprint(emissions)\nemissions.to_csv(\"/home/zsun/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")",
  "history_output" : "Running",
  "history_begin_time" : 1636037154808,
  "history_end_time" : 1636037155307,
  "history_notes" : null,
  "history_process" : "aowlun",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qs45wxc29bz",
  "history_input" : "import pandas as pd\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")\nprint(\"==================>\")\nprint(\"Describe data\")\nprint(emissions.describe())\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Check shape of data\")\nprint(emissions.shape)\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Check available columns\")\nprint(emissions.columns)\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Any NULL values in features?\")\nprint(emissions.isnull().sum())\nprint(\"==================>\")",
  "history_output" : "Running",
  "history_begin_time" : 1636037155934,
  "history_end_time" : 1636037156394,
  "history_notes" : null,
  "history_process" : "nj80ks",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "y78f5yj7e2s",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,8))  # 1 row, 2 columns\n\nemissions.plot(x='EPA_NO2/100000', y='TROPOMI*1000', kind='scatter', color='orange', ax=ax1)\n\nemissions.plot(x='Wind (Monthly)', y='Cloud Fraction (Monthly)', kind='scatter', color='green', ax=ax2)\n\nax1.set_xlabel('EPA_NO2/100000',fontsize=15)\nax2.set_xlabel('Wind (Monthly)',fontsize=15)\nax1.set_ylabel('TROPOMI*1000',fontsize=15)\nax2.set_ylabel('Cloud Fraction (Monthly)',fontsize=15)\n\nemissions.plot(x='Temp (Monthly)', y='EPA_NO2/100000', kind='scatter', color='blue', ax=ax3)\n\nemissions.plot(x='EPA_NO2/100000', y='Cloud Fraction (Monthly)', kind='scatter', color='red', ax=ax4)\n\nax3.set_xlabel('Temp (Monthly)',fontsize=15)\nax4.set_xlabel('EPA_NO2/100000',fontsize=15)\nax3.set_ylabel('TROPOMI*1000',fontsize=15)\nax4.set_ylabel('Cloud Fraction (Monthly)',fontsize=15)\n\nplt.savefig('/Users/uhhmed/geoweaver_demo/features.png')\n",
  "history_output" : "Running",
  "history_begin_time" : 1636037157317,
  "history_end_time" : 1636037158328,
  "history_notes" : null,
  "history_process" : "iihen4",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6kk07hd5lnb",
  "history_input" : "import pandas as pd\n\n\n\nregression_emissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\nregression_emissions['dayofyear'] = regression_emissions['Date'].dt.dayofyear\nregression_emissions['dayofweek'] = regression_emissions['Date'].dt.dayofweek\nregression_emissions['dayofmonth'] = regression_emissions['Date'].dt.day\nregression_emissions = regression_emissions.drop(columns=[\"Date\"])\n\n\nregression_emissions.to_csv('~/geoweaver_demo/preprocessed.csv')",
  "history_output" : "Running",
  "history_begin_time" : 1636037158404,
  "history_end_time" : 1636037158782,
  "history_notes" : null,
  "history_process" : "ypwf9s",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z246e2v91r6",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Running",
  "history_begin_time" : 1636037159337,
  "history_end_time" : 1636037160562,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5id31dlw4a7",
  "history_input" : "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nplt.style.use('fivethirtyeight')\n\nemissions_alabama_all = pd.read_csv('~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv',parse_dates=[\"Date\"])\n\nemissions_alabama_all['dayofyear'] = emissions_alabama_all['Date'].dt.dayofyear\nemissions_alabama_all['dayofweek'] = emissions_alabama_all['Date'].dt.dayofweek\nemissions_alabama_all['dayofmonth'] = emissions_alabama_all['Date'].dt.day\nemissions_alabama_all = emissions_alabama_all.drop(columns=[\"Date\"])\n\ndef create_dataset(dataset, look_back=7):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1): \n        a = dataset[i:(i+look_back), 1:] \n#         print(a)\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0]) \n    return np.array(dataX), np.array(dataY)\n    \ndataset = emissions_alabama_all.values\ndataset = dataset.astype('float32')\n\n# normalize the dataset\nlook_back = 7\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n\n# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n\n# reshape into X=t and Y=t+1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n\nprint(\"X_train's shape: \", trainX.shape)\nprint(\"y_train's shape: \", trainY.shape)\nprint(\"x_test's shape: \", testX.shape)\nprint(\"y_test's shape: \", testY.shape)\n\n# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 12, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 12, testX.shape[1]))\n\n# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(trainX.shape[1], trainX.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer='adadelta', metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(trainX, trainY, epochs=50, batch_size=1)\n\n# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n\nshowAccuracyMetrics(\"LSTM [Alabama Plant All features]: \", model, testY, testPredict)\n\n# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n\n# plot baseline and predictions\n#plt.plot(dataset[:,0])\n#plt.plot(trainPredictPlot[:,0])\n#plt.plot(testPredictPlot[:,0])\n#plt.legend([\"Data\", \"Train\", \"Test\"])\n#plt.title(\"One plant (ID 56, Alabama)\")\n#plt.savefig('/Users/uhhmed/geoweaver_demo/LSTM_model.png')\n",
  "history_output" : "Running",
  "history_begin_time" : 1636037160791,
  "history_end_time" : 1636037162076,
  "history_notes" : null,
  "history_process" : "w66uu5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xt5kr4hpsi5",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom sklearn.svm import SVR\n\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nregression_emissions = pd.read_csv('~/geoweaver_demo/preprocessed.csv')\n\nX = regression_emissions[['dayofyear']]\ny = regression_emissions['EPA_NO2/100000']\nxtrain, xtest, ytrain, ytest = train_test_split(X,y,test_size=0.30, random_state=42)\n\nxtrain = X.iloc[:116]\nytrain = y.iloc[:116]\nxtest = X.iloc[116:]\nytest = y.iloc[116:]\n\nsvr_rbf = SVR(kernel='rbf', C=1e4, gamma=0.35)\nsvr_rbf.fit(X, y)\ny_rbf = svr_rbf.predict(X)\n\nshowAccuracyMetrics(\"SVR: \", svr_rbf, y, y_rbf)\n\nplt.scatter(X, y, c='k', label='data')\nplt.plot(X, y_rbf, c='g', label='RBF model')\nplt.xlabel('dayofyear')\nplt.ylabel('EPA_NO2/100000')\nplt.title('Support Vector Regression')\nplt.legend()\nplt.savefig('/Users/uhhmed/geoweaver_demo/SVR_model.png')",
  "history_output" : "('Model ', 'SVR: ', ' Performance:')\n('   MAE: ', 0.05170117200405689)\n('   MSE: ', 0.0036857502571577103)\n('   R2: ', 0.5958888534234995)\nTraceback (most recent call last):\n  File \"SVR Model.py\", line 37, in <module>\n    plt.scatter(X, y, c='k', label='data')\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 3461, in scatter\n    ax = gca()\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 969, in gca\n    return gcf().gca(**kwargs)\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 586, in gcf\n    return figure()\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 533, in figure\n    **kwargs)\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backend_bases.py\", line 161, in new_figure_manager\n    return cls.new_figure_manager_given_figure(num, fig)\n  File \"/home/zsun/.local/lib/python2.7/site-packages/matplotlib/backends/_backend_tk.py\", line 1046, in new_figure_manager_given_figure\n    window = Tk.Tk(className=\"matplotlib\")\n  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 1828, in __init__\n    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)\n_tkinter.TclError: no display name and no $DISPLAY environment variable\n",
  "history_begin_time" : 1636037158959,
  "history_end_time" : 1636037160226,
  "history_notes" : null,
  "history_process" : "g7gk7m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "emmnrwaqzxa",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nregression_emissions = pd.read_csv('~/geoweaver_demo/preprocessed.csv')\n    \ntarget_column = ['EPA_NO2/100000'] \npredictors = ['TROPOMI*1000', 'dayofyear', 'dayofweek', 'dayofmonth']\n\nall_X = regression_emissions[predictors]\nall_y = regression_emissions[target_column]\n\n\nxtrain, xtest, ytrain, ytest = train_test_split(all_X,all_y,test_size=0.30, random_state=42)\n\n\nrandomForestregModel = RandomForestRegressor(max_depth=15)\nrandomForestregModel.fit(xtrain, np.ravel(ytrain))\n\nypred = randomForestregModel.predict(xtest)\n\n\nshowAccuracyMetrics(\"RF: \", randomForestregModel, ytest, ypred)\n\n\n\nfn=all_X.columns\ncn=all_y.columns\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (0.5,0.5), dpi=800)\nout = tree.plot_tree(randomForestregModel.estimators_[0],\n               feature_names = fn, \n#                class_names=cn,\n               filled = True,\n               );\n\nfor o in out:\n    arrow = o.arrow_patch\n    if arrow is not None:\n        arrow.set_edgecolor('black')\n        arrow.set_linewidth(.1)\n        \nplt.savefig('/Users/uhhmed/geoweaver_demo/tree.eps',format='eps',bbox_inches = \"tight\")",
  "history_output" : "Running",
  "history_begin_time" : 1636037161232,
  "history_end_time" : 1636037162517,
  "history_notes" : null,
  "history_process" : "jl0rv8",
  "host_id" : "100001",
  "indicator" : "Done"
}]
