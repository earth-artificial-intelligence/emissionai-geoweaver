[{
  "history_id" : "1zl5p9b62r9",
  "history_input" : "import pandas as pd\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\nemissions = pd.read_csv('https://raw.githubusercontent.com/ZihengSun/EmissionAI/main/data/tropomi_epa_kvps_NO2_2019_56.csv' , parse_dates=[\"Date\"])\nprint(emissions)\ndemo_dir = f\"{home}/geoweaver_demo/\"\nif not os.path.exists(demo_dir):\n\tos.mkdir(demo_dir)\nemissions.to_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")",
  "history_output" : "     FID   Latitude  ...  Precip (Monthly) Cloud Fraction (Monthly)\n0     56  31.488019  ...          0.000053                 0.470510\n1     56  31.488019  ...          0.000053                 0.470510\n2     56  31.488019  ...          0.000053                 0.470510\n3     56  31.488019  ...          0.000053                 0.470510\n4     56  31.488019  ...          0.000053                 0.470510\n..   ...        ...  ...               ...                      ...\n162   56  31.488019  ...          0.000052                 0.548777\n163   56  31.488019  ...          0.000052                 0.548777\n164   56  31.488019  ...          0.000052                 0.548777\n165   56  31.488019  ...          0.000052                 0.548777\n166   56  31.488019  ...          0.000052                 0.548777\n[167 rows x 10 columns]\n",
  "history_begin_time" : 1642227694595,
  "history_end_time" : 1642227704231,
  "history_notes" : null,
  "history_process" : "aowlun",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "n7qws5ugddw",
  "history_input" : "import pandas as pd\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\nemissions = pd.read_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")\nprint(\"==================>\")\nprint(\"Describe data\")\nprint(emissions.describe())\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Check shape of data\")\nprint(emissions.shape)\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Check available columns\")\nprint(emissions.columns)\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Any NULL values in features?\")\nprint(emissions.isnull().sum())\nprint(\"==================>\")",
  "history_output" : "==================>\nDescribe data\n       Unnamed: 0    FID  ...  Precip (Monthly)  Cloud Fraction (Monthly)\ncount   167.00000  167.0  ...        167.000000                167.000000\nmean     83.00000   56.0  ...          0.000052                  0.509011\nstd      48.35287    0.0  ...          0.000026                  0.048822\nmin       0.00000   56.0  ...          0.000004                  0.359887\n25%      41.50000   56.0  ...          0.000046                  0.486571\n50%      83.00000   56.0  ...          0.000047                  0.525576\n75%     124.50000   56.0  ...          0.000074                  0.526714\nmax     166.00000   56.0  ...          0.000098                  0.691063\n[8 rows x 10 columns]\n==================>\n==================>\nCheck shape of data\n(167, 11)\n==================>\n==================>\nCheck available columns\nIndex(['Unnamed: 0', 'FID', 'Latitude', 'Longitude', 'Date', 'EPA_NO2/100000',\n       'TROPOMI*1000', 'Wind (Monthly)', 'Temp (Monthly)', 'Precip (Monthly)',\n       'Cloud Fraction (Monthly)'],\n      dtype='object')\n==================>\n==================>\nAny NULL values in features?\nUnnamed: 0                  0\nFID                         0\nLatitude                    0\nLongitude                   0\nDate                        0\nEPA_NO2/100000              0\nTROPOMI*1000                0\nWind (Monthly)              0\nTemp (Monthly)              0\nPrecip (Monthly)            0\nCloud Fraction (Monthly)    0\ndtype: int64\n==================>\n",
  "history_begin_time" : 1642227705753,
  "history_end_time" : 1642227706588,
  "history_notes" : null,
  "history_process" : "nj80ks",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g1nsvkmb6qe",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,8))  # 1 row, 2 columns\n\nemissions.plot(x='EPA_NO2/100000', y='TROPOMI*1000', kind='scatter', color='orange', ax=ax1)\n\nemissions.plot(x='Wind (Monthly)', y='Cloud Fraction (Monthly)', kind='scatter', color='green', ax=ax2)\n\nax1.set_xlabel('EPA_NO2/100000',fontsize=15)\nax2.set_xlabel('Wind (Monthly)',fontsize=15)\nax1.set_ylabel('TROPOMI*1000',fontsize=15)\nax2.set_ylabel('Cloud Fraction (Monthly)',fontsize=15)\n\nemissions.plot(x='Temp (Monthly)', y='EPA_NO2/100000', kind='scatter', color='blue', ax=ax3)\n\nemissions.plot(x='EPA_NO2/100000', y='Cloud Fraction (Monthly)', kind='scatter', color='red', ax=ax4)\n\nax3.set_xlabel('Temp (Monthly)',fontsize=15)\nax4.set_xlabel('EPA_NO2/100000',fontsize=15)\nax3.set_ylabel('TROPOMI*1000',fontsize=15)\nax4.set_ylabel('Cloud Fraction (Monthly)',fontsize=15)\n\nplt.savefig(f'{home}/geoweaver_demo/features.png')\n",
  "history_output" : "",
  "history_begin_time" : 1642227708319,
  "history_end_time" : 1642227723160,
  "history_notes" : null,
  "history_process" : "iihen4",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4bm0jgmz3ux",
  "history_input" : "import pandas as pd\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\n\nregression_emissions = pd.read_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\nregression_emissions['dayofyear'] = regression_emissions['Date'].dt.dayofyear\nregression_emissions['dayofweek'] = regression_emissions['Date'].dt.dayofweek\nregression_emissions['dayofmonth'] = regression_emissions['Date'].dt.day\nregression_emissions = regression_emissions.drop(columns=[\"Date\"])\n\n\nregression_emissions.to_csv(f'{home}/geoweaver_demo/preprocessed.csv')",
  "history_output" : "",
  "history_begin_time" : 1642227724692,
  "history_end_time" : 1642227725675,
  "history_notes" : null,
  "history_process" : "ypwf9s",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "56xag07ctb4",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(\"~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('/Users/uhhmed/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/IvVcvGAPWicX6QtLoOIl42SpPq/DeepLearning_NN.py\", line 8, in <module>\n    from keras.models import Sequential\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n    from tensorflow.python import tf2\nModuleNotFoundError: No module named 'tensorflow'\n",
  "history_begin_time" : 1642227727243,
  "history_end_time" : 1642227730362,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5lj5i5v3d91",
  "history_input" : "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nplt.style.use('fivethirtyeight')\n\nemissions_alabama_all = pd.read_csv('~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv',parse_dates=[\"Date\"])\n\nemissions_alabama_all['dayofyear'] = emissions_alabama_all['Date'].dt.dayofyear\nemissions_alabama_all['dayofweek'] = emissions_alabama_all['Date'].dt.dayofweek\nemissions_alabama_all['dayofmonth'] = emissions_alabama_all['Date'].dt.day\nemissions_alabama_all = emissions_alabama_all.drop(columns=[\"Date\"])\n\ndef create_dataset(dataset, look_back=7):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1): \n        a = dataset[i:(i+look_back), 1:] \n#         print(a)\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0]) \n    return np.array(dataX), np.array(dataY)\n    \ndataset = emissions_alabama_all.values\ndataset = dataset.astype('float32')\n\n# normalize the dataset\nlook_back = 7\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n\n# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n\n# reshape into X=t and Y=t+1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n\nprint(\"X_train's shape: \", trainX.shape)\nprint(\"y_train's shape: \", trainY.shape)\nprint(\"x_test's shape: \", testX.shape)\nprint(\"y_test's shape: \", testY.shape)\n\n# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 12, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 12, testX.shape[1]))\n\n# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(trainX.shape[1], trainX.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer='adadelta', metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(trainX, trainY, epochs=50, batch_size=1)\n\n# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n\nshowAccuracyMetrics(\"LSTM [Alabama Plant All features]: \", model, testY, testPredict)\n\n# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n\n# plot baseline and predictions\n#plt.plot(dataset[:,0])\n#plt.plot(trainPredictPlot[:,0])\n#plt.plot(testPredictPlot[:,0])\n#plt.legend([\"Data\", \"Train\", \"Test\"])\n#plt.title(\"One plant (ID 56, Alabama)\")\n#plt.savefig('/Users/uhhmed/geoweaver_demo/LSTM_model.png')\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/IvVcvGAPWicX6QtLoOIl42SpPq/TrainModel_LSTM.py\", line 9, in <module>\n    from keras.models import Sequential\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n    from tensorflow.python import tf2\nModuleNotFoundError: No module named 'tensorflow'\n",
  "history_begin_time" : 1642227731775,
  "history_end_time" : 1642227733922,
  "history_notes" : null,
  "history_process" : "w66uu5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "li0297vfnti",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom sklearn.svm import SVR\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nregression_emissions = pd.read_csv(f'{home}/geoweaver_demo/preprocessed.csv')\n\nX = regression_emissions[['dayofyear']]\ny = regression_emissions['EPA_NO2/100000']\nxtrain, xtest, ytrain, ytest = train_test_split(X,y,test_size=0.30, random_state=42)\n\nxtrain = X.iloc[:116]\nytrain = y.iloc[:116]\nxtest = X.iloc[116:]\nytest = y.iloc[116:]\n\nsvr_rbf = SVR(kernel='rbf', C=1e4, gamma=0.35)\nsvr_rbf.fit(X, y)\ny_rbf = svr_rbf.predict(X)\n\nshowAccuracyMetrics(\"SVR: \", svr_rbf, y, y_rbf)\n\nplt.scatter(X, y, c='k', label='data')\nplt.plot(X, y_rbf, c='g', label='RBF model')\nplt.xlabel('dayofyear')\nplt.ylabel('EPA_NO2/100000')\nplt.title('Support Vector Regression')\nplt.legend()\nplt.savefig(f'{home}/geoweaver_demo/SVR_model.png')",
  "history_output" : "Model  SVR:   Performance:\n   MAE:  0.051701172004056876\n   MSE:  0.0036857502571577103\n   R2:  0.5958888534234995\n",
  "history_begin_time" : 1642227727017,
  "history_end_time" : 1642227730924,
  "history_notes" : null,
  "history_process" : "g7gk7m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "b5qbfddltih",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nregression_emissions = pd.read_csv(f'{home}/geoweaver_demo/preprocessed.csv')\n    \ntarget_column = ['EPA_NO2/100000'] \npredictors = ['TROPOMI*1000', 'dayofyear', 'dayofweek', 'dayofmonth']\n\nall_X = regression_emissions[predictors]\nall_y = regression_emissions[target_column]\n\n\nxtrain, xtest, ytrain, ytest = train_test_split(all_X,all_y,test_size=0.30, random_state=42)\n\n\nrandomForestregModel = RandomForestRegressor(max_depth=15)\nrandomForestregModel.fit(xtrain, np.ravel(ytrain))\n\nypred = randomForestregModel.predict(xtest)\n\n\nshowAccuracyMetrics(\"RF: \", randomForestregModel, ytest, ypred)\n\n\n\nfn=all_X.columns\ncn=all_y.columns\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (0.5,0.5), dpi=800)\nout = tree.plot_tree(randomForestregModel.estimators_[0],\n               feature_names = fn, \n#                class_names=cn,\n               filled = True,\n               );\n\nfor o in out:\n    arrow = o.arrow_patch\n    if arrow is not None:\n        arrow.set_edgecolor('black')\n        arrow.set_linewidth(.1)\n        \nplt.savefig(f'{home}/geoweaver_demo/tree.eps',format='eps',bbox_inches = \"tight\")",
  "history_output" : "Model  RF:   Performance:\n   MAE:  0.05822723859477125\n   MSE:  0.00594018426822043\n   R2:  0.2870956592528162\n",
  "history_begin_time" : 1642227732397,
  "history_end_time" : 1642227738360,
  "history_notes" : null,
  "history_process" : "jl0rv8",
  "host_id" : "100001",
  "indicator" : "Done"
}]
