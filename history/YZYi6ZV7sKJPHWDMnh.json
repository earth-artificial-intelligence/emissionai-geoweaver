[{
  "history_id" : "gla67vyufuf",
  "history_input" : "import pandas as pd\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\nemissions = pd.read_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")\nprint(\"==================>\")\nprint(\"Describe data\")\nprint(emissions.describe())\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Check shape of data\")\nprint(emissions.shape)\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Check available columns\")\nprint(emissions.columns)\nprint(\"==================>\")\nprint(\"==================>\")\nprint(\"Any NULL values in features?\")\nprint(emissions.isnull().sum())\nprint(\"==================>\")",
  "history_output" : "==================>\nDescribe data\n       Unnamed: 0    FID  ...  Precip (Monthly)  Cloud Fraction (Monthly)\ncount   167.00000  167.0  ...        167.000000                167.000000\nmean     83.00000   56.0  ...          0.000052                  0.509011\nstd      48.35287    0.0  ...          0.000026                  0.048822\nmin       0.00000   56.0  ...          0.000004                  0.359887\n25%      41.50000   56.0  ...          0.000046                  0.486571\n50%      83.00000   56.0  ...          0.000047                  0.525576\n75%     124.50000   56.0  ...          0.000074                  0.526714\nmax     166.00000   56.0  ...          0.000098                  0.691063\n[8 rows x 10 columns]\n==================>\n==================>\nCheck shape of data\n(167, 11)\n==================>\n==================>\nCheck available columns\nIndex(['Unnamed: 0', 'FID', 'Latitude', 'Longitude', 'Date', 'EPA_NO2/100000',\n       'TROPOMI*1000', 'Wind (Monthly)', 'Temp (Monthly)', 'Precip (Monthly)',\n       'Cloud Fraction (Monthly)'],\n      dtype='object')\n==================>\n==================>\nAny NULL values in features?\nUnnamed: 0                  0\nFID                         0\nLatitude                    0\nLongitude                   0\nDate                        0\nEPA_NO2/100000              0\nTROPOMI*1000                0\nWind (Monthly)              0\nTemp (Monthly)              0\nPrecip (Monthly)            0\nCloud Fraction (Monthly)    0\ndtype: int64\n==================>\n",
  "history_begin_time" : 1651521826216,
  "history_end_time" : 1651521826951,
  "history_notes" : null,
  "history_process" : "nj80ks",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3womtfrmq9r",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,8))  # 1 row, 2 columns\n\nemissions.plot(x='EPA_NO2/100000', y='TROPOMI*1000', kind='scatter', color='orange', ax=ax1)\n\nemissions.plot(x='Wind (Monthly)', y='Cloud Fraction (Monthly)', kind='scatter', color='green', ax=ax2)\n\nax1.set_xlabel('EPA_NO2/100000',fontsize=15)\nax2.set_xlabel('Wind (Monthly)',fontsize=15)\nax1.set_ylabel('TROPOMI*1000',fontsize=15)\nax2.set_ylabel('Cloud Fraction (Monthly)',fontsize=15)\n\nemissions.plot(x='Temp (Monthly)', y='EPA_NO2/100000', kind='scatter', color='blue', ax=ax3)\n\nemissions.plot(x='EPA_NO2/100000', y='Cloud Fraction (Monthly)', kind='scatter', color='red', ax=ax4)\n\nax3.set_xlabel('Temp (Monthly)',fontsize=15)\nax4.set_xlabel('EPA_NO2/100000',fontsize=15)\nax3.set_ylabel('TROPOMI*1000',fontsize=15)\nax4.set_ylabel('Cloud Fraction (Monthly)',fontsize=15)\n\nplt.savefig(f'{home}/geoweaver_demo/features.png')\n",
  "history_output" : "",
  "history_begin_time" : 1651521828492,
  "history_end_time" : 1651521833105,
  "history_notes" : null,
  "history_process" : "iihen4",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cqaj50h4ttp",
  "history_input" : "import pandas as pd\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\n\nregression_emissions = pd.read_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\nregression_emissions['dayofyear'] = regression_emissions['Date'].dt.dayofyear\nregression_emissions['dayofweek'] = regression_emissions['Date'].dt.dayofweek\nregression_emissions['dayofmonth'] = regression_emissions['Date'].dt.day\nregression_emissions = regression_emissions.drop(columns=[\"Date\"])\n\n\nregression_emissions.to_csv(f'{home}/geoweaver_demo/preprocessed.csv')",
  "history_output" : "",
  "history_begin_time" : 1651521834012,
  "history_end_time" : 1651521835046,
  "history_notes" : null,
  "history_process" : "ypwf9s",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pen85simzfo",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\nimport os\n\nhomedir = os.path.expanduser('~')\n\n\nplt.style.use('fivethirtyeight')\nemissions = pd.read_csv(f\"{homedir}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\",parse_dates=[\"Date\"])\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n    \nemissions['dayofyear'] = emissions['Date'].dt.dayofyear\nemissions['dayofweek'] = emissions['Date'].dt.dayofweek\nemissions['dayofmonth'] = emissions['Date'].dt.day\nemissions = emissions.drop(columns=[\"Date\"])\n\n# Separating dependednt & Indepented Variables \nx = emissions.iloc[:, emissions.columns != 'EPA_NO2/100000'].values\ny = emissions.iloc[:,  emissions.columns == 'EPA_NO2/100000']\n\n# show the shape of x and y to make sure they have the same length\n\n# Train Test Split at ratio 0.33\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Define Keras NN model\nmodel = Sequential()\nmodel.add(Dense(500, input_dim=12, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=8, validation_split = 0.2, epochs=50)\ny_test_pred = model.predict(x_test)\n\nshowAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)\n# \\\"Loss\\\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig(f'{homedir}/geoweaver_demo/NN_modelLoss.png')\n\ndef visualizeResults(modelname, x_test, y_test, pred):\n\t# Visualization\n    ## Check the fitting on training set\n\tplt.scatter(x_test[:,3], y_test, color='blue')\n\tplt.scatter(x_test[:,3], pred, color='black')\n\t#plt.scatter(y_test, pred, color='black')\n\tplt.title(modelname + ' Fit on testing set')\n\tplt.xlabel('TROMPOMI-Test')\n\tplt.ylabel('EPA-Test')\n\tplt.show()\n    \n#visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)",
  "history_output" : "",
  "history_begin_time" : 1651521836176,
  "history_end_time" : 1651521841660,
  "history_notes" : null,
  "history_process" : "3d9c6b",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xtoulbxfmf0",
  "history_input" : "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport tensorflow as tf\nimport math\n\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nplt.style.use('fivethirtyeight')\n\nemissions_alabama_all = pd.read_csv('~/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv',parse_dates=[\"Date\"])\n\nemissions_alabama_all['dayofyear'] = emissions_alabama_all['Date'].dt.dayofyear\nemissions_alabama_all['dayofweek'] = emissions_alabama_all['Date'].dt.dayofweek\nemissions_alabama_all['dayofmonth'] = emissions_alabama_all['Date'].dt.day\nemissions_alabama_all = emissions_alabama_all.drop(columns=[\"Date\"])\n\ndef create_dataset(dataset, look_back=7):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1): \n        a = dataset[i:(i+look_back), 1:] \n#         print(a)\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0]) \n    return np.array(dataX), np.array(dataY)\n    \ndataset = emissions_alabama_all.values\ndataset = dataset.astype('float32')\n\n# normalize the dataset\nlook_back = 7\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n\n# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n\n# reshape into X=t and Y=t+1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n\nprint(\"X_train's shape: \", trainX.shape)\nprint(\"y_train's shape: \", trainY.shape)\nprint(\"x_test's shape: \", testX.shape)\nprint(\"y_test's shape: \", testY.shape)\n\n# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 12, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 12, testX.shape[1]))\n\n# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(trainX.shape[1], trainX.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer='adadelta', metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\nhistory = model.fit(trainX, trainY, epochs=50, batch_size=1)\n\n# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n\nshowAccuracyMetrics(\"LSTM [Alabama Plant All features]: \", model, testY, testPredict)\n\n# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n\n# plot baseline and predictions\n#plt.plot(dataset[:,0])\n#plt.plot(trainPredictPlot[:,0])\n#plt.plot(testPredictPlot[:,0])\n#plt.legend([\"Data\", \"Train\", \"Test\"])\n#plt.title(\"One plant (ID 56, Alabama)\")\n#plt.savefig('/Users/uhhmed/geoweaver_demo/LSTM_model.png')\n",
  "history_output" : "2022-05-02 16:04:15.270040: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\nX_train's shape:  (103, 7, 12)\ny_train's shape:  (103,)\nx_test's shape:  (48, 7, 12)\ny_test's shape:  (48,)\nTraceback (most recent call last):\n  File \"TrainModel_LSTM.py\", line 73, in <module>\n    model.add(LSTM(4, input_shape=(trainX.shape[1], trainX.shape[2])))\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 522, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py\", line 208, in add\n    layer(x)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 660, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 945, in __call__\n    return self._functional_construction_call(inputs, args, kwargs,\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in _functional_construction_call\n    outputs = self._keras_tensor_symbolic_call(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 816, in _keras_tensor_symbolic_call\n    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 856, in _infer_output_signature\n    outputs = call_fn(inputs, *args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent_v2.py\", line 1139, in call\n    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 860, in _process_inputs\n    initial_state = self.get_initial_state(inputs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 642, in get_initial_state\n    init_state = get_initial_state_fn(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2508, in get_initial_state\n    return list(_generate_zero_filled_state_for_cell(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2990, in _generate_zero_filled_state_for_cell\n    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 3006, in _generate_zero_filled_state\n    return tf.nest.map_structure(create_zeros, state_size)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\", line 867, in map_structure\n    structure[0], [func(*x) for x in entries],\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\", line 867, in <listcomp>\n    structure[0], [func(*x) for x in entries],\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 3003, in create_zeros\n    return tf.zeros(init_state_size, dtype=dtype)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 2911, in wrapped\n    tensor = fun(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 2960, in zeros\n    output = _constant_if_small(zero, shape, dtype, name)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 2896, in _constant_if_small\n    if np.prod(shape) < 1000:\n  File \"<__array_function__ internals>\", line 180, in prod\n  File \"/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 3088, in prod\n    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n  File \"/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 867, in __array__\n    raise NotImplementedError(\nNotImplementedError: Cannot convert a symbolic Tensor (lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
  "history_begin_time" : 1651521842085,
  "history_end_time" : 1651521856059,
  "history_notes" : null,
  "history_process" : "w66uu5",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "56j8xkdmsfz",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom sklearn.svm import SVR\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nregression_emissions = pd.read_csv(f'{home}/geoweaver_demo/preprocessed.csv')\n\nX = regression_emissions[['dayofyear']]\ny = regression_emissions['EPA_NO2/100000']\nxtrain, xtest, ytrain, ytest = train_test_split(X,y,test_size=0.30, random_state=42)\n\nxtrain = X.iloc[:116]\nytrain = y.iloc[:116]\nxtest = X.iloc[116:]\nytest = y.iloc[116:]\n\nsvr_rbf = SVR(kernel='rbf', C=1e4, gamma=0.35)\nsvr_rbf.fit(X, y)\ny_rbf = svr_rbf.predict(X)\n\nshowAccuracyMetrics(\"SVR: \", svr_rbf, y, y_rbf)\n\nplt.scatter(X, y, c='k', label='data')\nplt.plot(X, y_rbf, c='g', label='RBF model')\nplt.xlabel('dayofyear')\nplt.ylabel('EPA_NO2/100000')\nplt.title('Support Vector Regression')\nplt.legend()\nplt.savefig(f'{home}/geoweaver_demo/SVR_model.png')",
  "history_output" : "Model  SVR:   Performance:\n   MAE:  0.051701172004056876\n   MSE:  0.0036857502571577103\n   R2:  0.5958888534234995\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 142, in pandas._libs.index.IndexEngine.get_loc\nTypeError: '(slice(None, None, None), None)' is an invalid key\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"SVR Model.py\", line 40, in <module>\n    plt.plot(X, y_rbf, c='g', label='RBF model')\n  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\", line 2757, in plot\n    return gca().plot(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\", line 1632, in plot\n    lines = [*self._get_lines(*args, data=data, **kwargs)]\n  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\", line 312, in __call__\n    yield from self._plot_args(this, kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\", line 487, in _plot_args\n    x = _check_1d(xy[0])\n  File \"/opt/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\", line 1327, in _check_1d\n    ndim = x[:, None].ndim\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3628, in get_loc\n    self._check_indexing_error(key)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5637, in _check_indexing_error\n    raise InvalidIndexError(key)\npandas.errors.InvalidIndexError: (slice(None, None, None), None)\n",
  "history_begin_time" : 1651521836171,
  "history_end_time" : 1651521841627,
  "history_notes" : null,
  "history_process" : "g7gk7m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kwo3tixxpkx",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\ndef showAccuracyMetrics(mlmethod, model, y_test, y_pred):    \n\tprint(\"Model \", mlmethod, \" Performance:\")\n\t#print(y_test.shape, y_pred.shape)\t\n\tmae = metrics.mean_absolute_error(y_test, \t\t\ty_pred)\n\tmse = metrics.mean_squared_error(y_test, \t\t\ty_pred)\n\tr2 = metrics.r2_score(y_test, y_pred)\n\tprint(\"   MAE: \", mae)\n\tprint(\"   MSE: \", mse)    \n\tprint(\"   R2: \", r2)\n\nregression_emissions = pd.read_csv(f'{home}/geoweaver_demo/preprocessed.csv')\n    \ntarget_column = ['EPA_NO2/100000'] \npredictors = ['TROPOMI*1000', 'dayofyear', 'dayofweek', 'dayofmonth']\n\nall_X = regression_emissions[predictors]\nall_y = regression_emissions[target_column]\n\n\nxtrain, xtest, ytrain, ytest = train_test_split(all_X,all_y,test_size=0.30, random_state=42)\n\n\nrandomForestregModel = RandomForestRegressor(max_depth=15)\nrandomForestregModel.fit(xtrain, np.ravel(ytrain))\n\nypred = randomForestregModel.predict(xtest)\n\n\nshowAccuracyMetrics(\"RF: \", randomForestregModel, ytest, ypred)\n\n\n\nfn=all_X.columns\ncn=all_y.columns\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (0.5,0.5), dpi=800)\nout = tree.plot_tree(randomForestregModel.estimators_[0],\n               feature_names = fn, \n#                class_names=cn,\n               filled = True,\n               );\n\nfor o in out:\n    arrow = o.arrow_patch\n    if arrow is not None:\n        arrow.set_edgecolor('black')\n        arrow.set_linewidth(.1)\n        \nplt.savefig(f'{home}/geoweaver_demo/tree.eps',format='eps',bbox_inches = \"tight\")",
  "history_output" : "",
  "history_begin_time" : 1651521842683,
  "history_end_time" : 1651521856088,
  "history_notes" : null,
  "history_process" : "jl0rv8",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ycvv4agweyq",
  "history_input" : "# Write first python in Geoweaver",
  "history_output" : "",
  "history_begin_time" : 1651521856887,
  "history_end_time" : 1651521857082,
  "history_notes" : null,
  "history_process" : "kce2jy",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1mybd3bizx0",
  "history_input" : "import pandas as pd\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\nemissions = pd.read_csv('https://raw.githubusercontent.com/ZihengSun/EmissionAI/main/data/tropomi_epa_kvps_NO2_2019_56.csv' , parse_dates=[\"Date\"])\nprint(emissions)\ndemo_dir = f\"{home}/geoweaver_demo/\"\nif not os.path.exists(demo_dir):\n\tos.mkdir(demo_dir)\nemissions.to_csv(f\"{home}/geoweaver_demo/tropomi_epa_kvps_NO2_2019_56.csv\")",
  "history_output" : "     FID   Latitude  ...  Precip (Monthly) Cloud Fraction (Monthly)\n0     56  31.488019  ...          0.000053                 0.470510\n1     56  31.488019  ...          0.000053                 0.470510\n2     56  31.488019  ...          0.000053                 0.470510\n3     56  31.488019  ...          0.000053                 0.470510\n4     56  31.488019  ...          0.000053                 0.470510\n..   ...        ...  ...               ...                      ...\n162   56  31.488019  ...          0.000052                 0.548777\n163   56  31.488019  ...          0.000052                 0.548777\n164   56  31.488019  ...          0.000052                 0.548777\n165   56  31.488019  ...          0.000052                 0.548777\n166   56  31.488019  ...          0.000052                 0.548777\n[167 rows x 10 columns]\n",
  "history_begin_time" : 1651521822976,
  "history_end_time" : 1651521824461,
  "history_notes" : null,
  "history_process" : "aowlun",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "728n3ra6e4b",
  "history_input" : "\"\"\" \nCheck if host machine contains required packages to run this process. \nIf packages are not available, this process will install them.\nThis process will get surface temperature, bias-corrected precipitation, \ncloud fraction, and surface wind speed from different MERRA-2 collections,\nresample them to daily data and save to a csv file.\nUser can specify duration of data to extract in lines (67 - 71).\nNOTE: This process also needs a NASA Earthdata account.\nPlease update line 46 with a username and password to proceed with execution.\n \"\"\"\n\nimport sys\nimport subprocess\nimport pkg_resources\n\n# Required packages to run this process.\nrequired = {'xarray', 'netCDF4', 'dask', 'pandas'}\ninstalled = {pkg.key for pkg in pkg_resources.working_set}\nmissing = required - installed\n\nif missing:\n    print(\"Packages missing and will be installed: \", missing)\n    python = sys.executable\n    subprocess.check_call(\n        [python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n\n################################\n#  END OF PACKAGES VALIDATION  #\n################################\n\n\n##############################################\n#  NASA Earthdata account credentials setup  #\n##############################################\n\n# get current user home directory to create necessary file for earthdata access.\nfrom os.path import expanduser\nhome_dir = expanduser(\"~\")\n\n# create .netrc file to insert earthdata username and password\nopen(home_dir + '/.netrc', 'w').close()\nopen(home_dir + '/.urs_cookies', 'w').close()\nsubprocess.check_call(\n    ['echo \"machine urs.earthdata.nasa.gov login <username> password <password>\" >> ' + home_dir + '/.netrc'], shell=True)\n\nopen(home_dir + '/.dodsrc', 'w').close()\nsubprocess.check_call(\n    ['echo \"HTTP.COOKIEJAR=' + home_dir + '/.urs_cookies\" >> ' + home_dir + '/.dodsrc'], shell=True)\nsubprocess.check_call(\n    ['echo \"HTTP.NETRC=' + home_dir + '/.netrc\" >> ' + home_dir + '/.dodsrc'], shell=True)\n\n#####################################################\n#  END OF NASA Earthdata account credentials setup  #\n#####################################################\n\n\n\"\"\" Extract MERRA-2 Hourly data for the month of January 2019 \"\"\"\nimport pandas as pd\nimport dask\nimport netCDF4\nimport xarray as xr\n\n\n# Time frame of MERRA-2 data to collect\nyear = '2019'\nmonth_begin = '01'\nmonth_end = '03'\nday_begin = '01'\nday_end = '31'\n\n# MERRA-2 M2I1NXASM collection (hourly) to get Temp and Wind variables (T2M, V2M).\ncollection_shortname = 'M2I1NXASM'\ncollection_longname = 'inst1_2d_asm_Nx'\ncollection_number = 'MERRA2_400'\nMERRA2_version = '5.12.4'\n\n\n# OPeNDAP URL\nurl = 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/{}.{}/{}'.format(\n    collection_shortname, MERRA2_version, year)\nfiles_month = ['{}/{}/{}.{}.{}{}.nc4'.format(url, month_days[0:2], collection_number, collection_longname, year, month_days)\n               for month_days in pd.date_range(year + '-' + month_begin + '-' + day_begin, year + '-' + month_end + '-' + day_end, freq='D').strftime(\"%m%d\").tolist()]\n\n\n# Get the number of files\nlen_files_month = len(files_month)\n\n\nprint(\"{} files to be opened:\".format(len_files_month))\nprint(\"files_month\", files_month)\n\n# Read dataset URLs\nds = xr.open_mfdataset(files_month)\n\n\n# MERRA-2 M2T1NXLND collection (hourly) to get Total precipitation variable (PRECTOTLAND).\ncollection_shortname = 'M2T1NXLND'\ncollection_longname = 'tavg1_2d_lnd_Nx'\ncollection_number = 'MERRA2_400'\nMERRA2_version = '5.12.4'\n\n\n# OPeNDAP URL\nurl = 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/{}.{}/{}'.format(\n    collection_shortname, MERRA2_version, year)\nfiles_month = ['{}/{}/{}.{}.{}{}.nc4'.format(url, month_days[0:2], collection_number, collection_longname, year, month_days)\n               for month_days in pd.date_range(year + '-' + month_begin + '-' + day_begin, year + '-' + month_end + '-' + day_end, freq='D').strftime(\"%m%d\").tolist()]\n\n# Get the number of files\nlen_files_month = len(files_month)\n\n\nprint(\"{} files to be opened:\".format(len_files_month))\nprint(\"files_month\", files_month)\n\n# Read dataset URLs\nds_precip = xr.open_mfdataset(files_month)\n\n\n# MERRA-2 M2T1NXRAD collection (hourly) to get Cloud Fraction variable (CLDTOT).\ncollection_shortname = 'M2T1NXRAD'\ncollection_longname = 'tavg1_2d_rad_Nx'\ncollection_number = 'MERRA2_400'\nMERRA2_version = '5.12.4'\n\n\n# OPeNDAP URL\nurl = 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/{}.{}/{}'.format(\n    collection_shortname, MERRA2_version, year)\nfiles_month = ['{}/{}/{}.{}.{}{}.nc4'.format(url, month_days[0:2], collection_number, collection_longname, year, month_days)\n               for month_days in pd.date_range(year + '-' + month_begin + '-' + day_begin, year + '-' + month_end + '-' + day_end, freq='D').strftime(\"%m%d\").tolist()]\n\n# Get the number of files\nlen_files_month = len(files_month)\n\n\nprint(\"{} files to be opened:\".format(len_files_month))\nprint(\"files_month\", files_month)\n\n# Read dataset URLs\nds_cloud = xr.open_mfdataset(files_month)\n\n\n# extract values from all datasets based on location (Alabama plant)\nalabama_plant_temp_wind = ds.sel(lat=31.48, lon=-87.91, method='nearest')\nalabama_plant_temp_wind = alabama_plant_temp_wind[['T2M', 'V2M']]\n\nalabama_plant_precip = ds_precip.sel(lat=31.48, lon=-87.91, method='nearest')\nalabama_plant_precip = alabama_plant_precip[['PRECTOTLAND']]\n\nalabama_plant_cloud = ds_cloud.sel(lat=31.48, lon=-87.91, method='nearest')\nalabama_plant_cloud = alabama_plant_cloud[['CLDTOT']]\n\n\n# Resample all datasets by day\nalabama_plant_temp_wind_mean = alabama_plant_temp_wind.resample(\n    time=\"1D\").mean(dim='time', skipna=True)\nalabama_plant_precip_mean = alabama_plant_precip.resample(\n    time=\"1D\").mean(dim='time', skipna=True)\nalabama_plant_cloud_mean = alabama_plant_cloud.resample(\n    time=\"1D\").mean(dim='time', skipna=True)\n\n# Convert datasets to pandas df and save to CSV file.\nalabama_plant_temp_wind_mean_df = alabama_plant_temp_wind_mean.to_dataframe()\nalabama_plant_precip_mean_df = alabama_plant_precip_mean.to_dataframe()\nalabama_plant_cloud_mean_df = alabama_plant_cloud_mean.to_dataframe()\n\nmerged_dfs = alabama_plant_temp_wind_mean_df.merge(\n    alabama_plant_precip_mean_df, on='time').merge(alabama_plant_cloud_mean_df, on='time')\nmerged_dfs = merged_dfs[['T2M', 'V2M', 'PRECTOTLAND', 'CLDTOT']]\n\nmerged_dfs.to_csv(home_dir + '/merra2_daily_mean_January_2019.csv')",
  "history_output" : "syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: HTTP^ Basic: Access denied.\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: HTTP^ Basic: Access denied.\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: HTTP^ Basic: Access denied.\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: HTTP^ Basic: Access denied.\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: HTTP^ Basic: Access denied.\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: HTTP^ Basic: Access denied.\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: HTTP^ Basic: Access denied.\nPackages missing and will be installed:  {'netCDF4'}\n90 files to be opened:\nfiles_month ['https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190101.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190102.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190103.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190104.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190105.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190106.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190107.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190108.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190109.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190110.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190111.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190112.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190113.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190114.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190115.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190116.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190117.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190118.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190119.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190120.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190121.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190122.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190123.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190124.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190125.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190126.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190127.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190128.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190129.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190130.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/01/MERRA2_400.inst1_2d_asm_Nx.20190131.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190201.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190202.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190203.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190204.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190205.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190206.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190207.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190208.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190209.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190210.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190211.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190212.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190213.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190214.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190215.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190216.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190217.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190218.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190219.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190220.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190221.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190222.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190223.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190224.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190225.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190226.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190227.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/02/MERRA2_400.inst1_2d_asm_Nx.20190228.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190301.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190302.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190303.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190304.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190305.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190306.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190307.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190308.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190309.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190310.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190311.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190312.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190313.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190314.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190315.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190316.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190317.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190318.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190319.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190320.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190321.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190322.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190323.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190324.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190325.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190326.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190327.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190328.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190329.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190330.nc4', 'https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/2019/03/MERRA2_400.inst1_2d_asm_Nx.20190331.nc4']\nTraceback (most recent call last):\n  File \"data_merra2_extraction.py\", line 93, in <module>\n    ds = xr.open_mfdataset(files_month)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/api.py\", line 908, in open_mfdataset\n    datasets = [open_(p, **open_kwargs) for p in paths]\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/api.py\", line 908, in <listcomp>\n    datasets = [open_(p, **open_kwargs) for p in paths]\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/api.py\", line 495, in open_dataset\n    backend_ds = backend.open_dataset(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 564, in open_dataset\n    ds = store_entrypoint.open_dataset(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/store.py\", line 27, in open_dataset\n    vars, attrs, coord_names = conventions.decode_cf_variables(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/conventions.py\", line 512, in decode_cf_variables\n    new_vars[k] = decode_cf_variable(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/conventions.py\", line 360, in decode_cf_variable\n    var = times.CFDatetimeCoder(use_cftime=use_cftime).decode(var, name=name)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/coding/times.py\", line 526, in decode\n    dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/coding/times.py\", line 149, in _decode_cf_datetime_dtype\n    [first_n_items(values, 1) or [0], last_item(values) or [0]]\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/core/formatting.py\", line 72, in first_n_items\n    return np.asarray(array).flat[:n_desired]\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/core/indexing.py\", line 357, in __array__\n    return np.asarray(self.array, dtype=dtype)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/core/indexing.py\", line 422, in __array__\n    return np.asarray(array[self.key], dtype=None)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 90, in __getitem__\n    return indexing.explicit_indexing_adapter(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/core/indexing.py\", line 711, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 103, in _getitem\n    array = getitem(original_array, key)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/common.py\", line 64, in robust_getitem\n    return array[key]\n  File \"src/netCDF4/_netCDF4.pyx\", line 4406, in netCDF4._netCDF4.Variable.__getitem__\n  File \"src/netCDF4/_netCDF4.pyx\", line 5350, in netCDF4._netCDF4.Variable._get\n  File \"src/netCDF4/_netCDF4.pyx\", line 1927, in netCDF4._netCDF4._ensure_nc_success\nRuntimeError: NetCDF: Authorization failure\n",
  "history_begin_time" : 1651521746763,
  "history_end_time" : 1651521821171,
  "history_notes" : null,
  "history_process" : "o0lq93",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hhfsfcuriet",
  "history_input" : "import json\nimport pandas as pd\nimport ee\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\n# identify a 500 meter buffer around our Point Of Interest (POI)\npoi = ee.Geometry.Point(-87.910747, 31.488019).buffer(500)\n\nGet TROPOMI NRTI Image Collection for GoogleEarth Engine\ntropomiCollection = ee.ImageCollection(\"COPERNICUS/S5P\n/NRTI/L3_NO2\").filterDate('2019-01-01','2019-03-31')\n\ndef poi_mean(img):\n    # This function will reduce all the points in the area we specifed in \"poi\" \n    and average all the data into a single daily value\n    mean = img.reduceRegion(reducer=ee.Reducer.mean(), \n    geometry=poi,scale=250).get('tropospheric_NO2_column_number_density')\n    return img.set('date', img.date().format()).set('mean',mean)\n    \n# Map function to our ImageCollection\npoi_reduced_imgs = tropomiCollection.map(poi_mean)\nnested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2)['date','mean']).values().get(0)\n\n# we need to call the callback method \"getInfo\" to retrieve the data\ndf = pd.DataFrame(nested_list.getInfo(), columns=['date','tropomi_no2_mean'])\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\t# Scaling the data to later match our target feature scale\ndf['tropomi_no2_mean'] = df['tropomi_no2_mean']*1000\n# Save data to CSV file\ndf.to_csv('tropomi_no2.csv')\n\n",
  "history_output" : "  File \"data_tropomi_extraction.py\", line 14\n    Get TROPOMI NRTI Image Collection for GoogleEarth Engine\n        ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1651521746742,
  "history_end_time" : 1651521747702,
  "history_notes" : null,
  "history_process" : "wji81a",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jl2bpa16qcm",
  "history_input" : "import json\nimport pandas as pd\nimport ee\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\n# identify a 500 meter buffer around our Point Of Interest (POI)\npoi = ee.Geometry.Point(-87.910747, 31.488019).buffer(500)\n\nmcd19a2 = ee.ImageCollection(\"MODIS/006/MCD19A2_GRANULES\").filterDate('2019-01-01','2019-03-31')\ndef poi_mean(img):\n    mean = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=250).get('Optical_Depth_047')\n    return img.set('date', img.date().format()).set('mean',mean)\n\n    \n# Map function to our ImageCollection\npoi_reduced_imgs = tropomiCollection.map(poi_mean)\nnested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2)['date','mean']).values().get(0)\n\n# we need to call the callback method \"getInfo\" to retrieve the data\ndf = pd.DataFrame(nested_list.getInfo(), columns=['date','tropomi_no2_mean'])\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\t# Scaling the data to later match our target feature scale\ndf['tropomi_no2_mean'] = df['tropomi_no2_mean']*1000\n# Save data to CSV file\ndf.to_csv('tropomi_no2.csv')\n\n",
  "history_output" : "",
  "history_begin_time" : 1651521746742,
  "history_end_time" : 1651521747716,
  "history_notes" : null,
  "history_process" : "6kcl4m",
  "host_id" : "100001",
  "indicator" : "Done"
}]
